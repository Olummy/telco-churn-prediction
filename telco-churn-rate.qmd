---
title: "Telecom Company Churn Rate"
subtitle: "Telecom Company Service Performance Analysis"
author: "Adeyinka Ologun"
format: 
  html:
    theme: journal
    code-copy: true
    code-fold: show
    toc: true
    toc-depth: 3
    fig-width: 8
    fig-height: 5
    toc-title: "Contents"
    self-contained: true
editor: visual
---


# Preamble

## Packages

```{r}
#| warning: false
#| message: false
#| label: load-package


if(!require(pacman)) 
  install.packages("pacman")

pacman::p_load(
  tidyverse,
  readxl,
  scales,
  ggrepel,
  skimr,
  tidymodels,
  stacks,
  magrittr,
  tictoc,
  bonsai,
  lightgbm,
  DALEX,
  DALEXtra,
  patchwork,
  bestNormalize,
  embed,
  learntidymodels,
  baguette,
  discrim
  
)

options(scipen = 999, digits = 2)
tidymodels_prefer()
```

## Read Data File

```{r}
#| warning: false
#| message: false
#| label: read-data

churn_tbl <- read_excel("Telecom Churn Rate Dataset.xlsx") 

```


### Data Wrangling

```{r}
#| warning: false
#| message: false
#| label: data-wrangling

churn_tbl <-
  churn_tbl %>% 
  mutate(SeniorCitizen = if_else(SeniorCitizen == 0, "No", "Yes")) %>% 
  mutate_if(is.character, as.factor)

```

### Quick Data Summary

let's have a quick look at the dataset


```{r}
#| comment: ""
#| label: glimpse
#| warning: false
#| message: false


glimpse(churn_tbl)
skim(churn_tbl)
```

# Exploratory Data Analysis


```{r}
#| warning: false
#| message: false
#| label: churn-proportion


churn_tbl %>% 
  group_by(Churn) %>% 
  summarise(Freq = n()) %>% 
  mutate(Prop = Freq/sum(Freq)) %>% 
  ggplot(aes(x = 2, y = Prop, fill = reorder(Churn, -Prop))) +
  geom_bar(stat ="identity", width = 1, color = "white") +
  xlim(0.3, 2.5) +
  coord_polar(theta = "y",  start = 0) +
  theme_void() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "",
       y = "",
       title = "Historical churn status",
       fill = "Churn?") +
  geom_text_repel(aes(label = paste0(round(Prop*100,1),"%")), size = 3, position = position_stack(vjust = 0.7)) +
    #scale_fill_brewer(palette = "Blues", direction = -1) +
    theme(legend.position = "right")
```



```{r}
#| warning: false
#| message: false
#| label: gender-distribution


churn_tbl %>% 
  group_by(gender) %>% 
  summarise(Freq = n()) %>% 
  mutate(Prop = Freq/sum(Freq)) %>% 
  ggplot(aes(x = 2, y = Prop, fill = reorder(gender, -Prop))) +
  geom_bar(stat ="identity", width = 1, color = "white") +
  xlim(0.3, 2.5) +
  coord_polar(theta = "y",  start = 0) +
  theme_void() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "",
       y = "",
       title = "Customer gender distribution",
       fill = "") +
  geom_text_repel(aes(label = paste0(round(Prop*100,1),"%")), size = 3, position = position_stack(vjust = 0.7)) +
    #scale_fill_brewer(palette = "Blues", direction = -1) +
    theme(legend.position = "right")
```


```{r}
#| warning: false
#| message: false
#| label: contractType-distribution


churn_tbl %>% 
  group_by(Contract) %>% 
  summarise(Freq = n()) %>% 
  mutate(Prop = Freq/sum(Freq)) %>% 
  ggplot(aes(x = 2, y = Prop, fill = reorder(Contract, -Prop))) +
  geom_bar(stat ="identity", width = 1, color = "white") +
  xlim(0.3, 2.5) +
  coord_polar(theta = "y",  start = 0) +
  theme_void() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "",
       y = "",
       title = "Customer contract type distribution",
       fill = "") +
  geom_text_repel(aes(label = paste0(round(Prop*100,1),"%")), size = 3, position = position_stack(vjust = 0.7)) +
    #scale_fill_brewer(palette = "Blues", direction = -1) +
    theme(legend.position = "right")
```




```{r}
#| warning: false
#| message: false
#| label: paperlessBilling-distribution


churn_tbl %>% 
  group_by(PaperlessBilling) %>% 
  summarise(Freq = n()) %>% 
  mutate(Prop = Freq/sum(Freq)) %>% 
  ggplot(aes(x = 2, y = Prop, fill = reorder(PaperlessBilling, -Prop))) +
  geom_bar(stat ="identity", width = 1, color = "white") +
  xlim(0.3, 2.5) +
  coord_polar(theta = "y",  start = 0) +
  theme_void() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "",
       y = "",
       title = "Paperless billing distribution",
       fill = "Paperless billing?") +
  geom_text_repel(aes(label = paste0(round(Prop*100,1),"%")), size = 3, position = position_stack(vjust = 0.7)) +
    #scale_fill_brewer(palette = "Blues", direction = -1) +
    theme(legend.position = "right")
```




```{r}
#| warning: false
#| message: false
#| label: paymentMethod-distribution


churn_tbl %>% 
  group_by(PaymentMethod) %>% 
  summarise(Freq = n()) %>% 
  mutate(Prop = Freq/sum(Freq)) %>% 
  ggplot(aes(x = 2, y = Prop, fill = reorder(PaymentMethod, -Prop))) +
  geom_bar(stat ="identity", width = 1, color = "white") +
  xlim(0.3, 2.5) +
  coord_polar(theta = "y",  start = 0) +
  theme_void() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "",
       y = "",
       title = "Customer payment method distribution",
       fill = "") +
  geom_text_repel(aes(label = paste0(round(Prop*100,1),"%")), size = 3, position = position_stack(vjust = 0.7)) +
    #scale_fill_brewer(palette = "Blues", direction = -1) +
    theme(legend.position = "right")
```






```{r}
#| warning: false
#| message: false
#| label: monthlyCharges-yearlyCharges-Tenure
#| fig-width: 12
#| fig-height: 5


tenure <- 
  churn_tbl %>% 
  ggplot(aes(tenure)) +
  geom_histogram(fill = "steelblue", color = "white", na.rm = TRUE) +
  labs(x = "Tenure",
       title = "Customer tenure")+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))


monthly <- 
  churn_tbl %>% 
  ggplot(aes(MonthlyCharges)) +
  geom_histogram(fill = "tomato", color = "white", na.rm = TRUE) +
  labs(x = "Monthly charges",
       title = "Customer monthly charges distribution")+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))


total <- 
  churn_tbl %>% 
  ggplot(aes(TotalCharges)) +
  geom_histogram(fill = "coral", color = "white", na.rm = TRUE) +
  labs(x = "Total charges",
       title = "Customer total charges distribution")+
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9))

(tenure)/(monthly + total)
```


## Tickets 

```{r}
#| warning: false
#| message: false
#| label: tickets
#| fig-width: 10
#| fig-height: 5


adminTickets <- 
  churn_tbl %>% 
  count(numAdminTickets) %>% 
  ggplot(aes(x = factor(numAdminTickets), y = n)) +
  geom_bar(fill = "steelblue", color = "white", na.rm = TRUE, stat = "identity") +
  labs(x = "Tickets",
       y = "count",
       title = "Admin tickets")+
  scale_y_continuous(labels = comma) +
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9)) +
  geom_text(aes(label = format(n, big.mark = ",")), size = 3)



techTickets <- 
  churn_tbl %>% 
  count(numTechTickets) %>% 
  ggplot(aes(x = factor(numTechTickets), y = n)) +
  geom_bar(fill = "tomato", color = "white", na.rm = TRUE, stat = "identity") +
  labs(x = "Tickets",
       y = "count",
       title = "Tech tickets")+
  scale_y_continuous(labels = comma) +
  theme(axis.title.x = element_text(size = 9))+
  theme(axis.title.y = element_text(size = 9)) +
  geom_text(aes(label = format(n, big.mark = ",")), size = 3)



(adminTickets)/(techTickets)
```



# Modeling

## Data Partitioning

For the analyses, we start by holding back a testing set with `initial_split()`. The remaining data are split into `training` and `validation` sets:

```{r}
#| label: data-split
#| warning: false
#| message: false

# drop the customerID field

churn_tbl <- 
  churn_tbl %>% 
  select(-customerID)

set.seed(1601)

churn_split <- initial_split(churn_tbl,
                            prop = 0.75,
                            strata = Churn)
churn_train <- churn_split %>% 
  training()
churn_test <- churn_split %>% 
  testing()

set.seed(1602)

churn_val <- validation_split(churn_train, strata = Churn, prop = 4/5)

churn_val$splits[[1]]
```



------------------------------------------------------------------------

## Recipes in the wild

```{r}
#| label: recipe-wkflw
#| warning: false
#| message: false


churn_rec <- recipe(Churn ~ ., 
                  data = analysis(churn_val$splits[[1]])) %>% 

# Now add preprocessing steps to the recipe:

  step_impute_knn(all_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_orderNorm(all_numeric_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>%
  step_spatialsign(all_numeric_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>%
  step_other(all_nominal_predictors()) %>% 
  step_filter_missing(all_nominal_predictors(), threshold = 0) 


churn_rec_trained <- 
  churn_rec %>% 
  prep(log_changes = TRUE)
 
churn_rec_trained

```


### Baking the Recipe

```{r}
#| label: baking
#| warning: false
#| message: false

churn_validation <- churn_val$splits %>% pluck(1) %>% assessment()
churn_val_processed <- bake(churn_rec_trained, new_data = churn_validation)

```



------------------------------------------------------------------------

> show the histograms of the `Tenure` predictor before and after the recipe was prepared:

```{r}
#| label: compare-original-vs-processed-data
#| warning: false
#| message: false
#| fig-width: 10

p1 <- 
  churn_validation %>% 
  ggplot(aes(x = tenure)) +
  geom_histogram(bins = 30, color = "white", fill = "blue", alpha = 1/3) +
  ggtitle("Original validation set data")


p2 <- 
  churn_val_processed %>% 
  ggplot(aes(x = tenure)) +
  geom_histogram(bins = 30, color = "white", fill = "red", alpha = 1/3) +
  ggtitle("Processed validation set data")

p1 + p2

```



## Feature Extraction

```{r}
plot_validation_results <- function(recipe, dat = assessment(churn_val$splits[[1]])){
  set.seed(1)
  plot_data <- 
    recipe %>% 
    prep() %>% 
    bake(new_data = dat, all_predictors(), all_outcomes()) %>% 
    sample_n(120)
  
  nms <- names(plot_data)
  x_name <- sym(nms[1])
  y_name <- sym(nms[2])
  
  plot_data %>% 
    ggplot(aes(x = !!x_name, y = !!y_name, col = Churn,
               fill = Churn, pch = Churn)) +
    geom_point(alpha =0.9) +
    scale_shape_manual(values = 1:2) +
    coord_obs_pred() +
    theme_bw()
}
```

### Principal Component Analysis

```{r}
#| warning: false
#| message: false
#| label: pca-visuals
#| fig-width: 10


churn_rec_trained %>% 
  step_pca(all_numeric_predictors(), num_comp = 4) %>% 
  plot_validation_results() +
  ggtitle("Principal Component Analysis")

# plot the pcas with loadings

churn_rec_trained %>% 
  step_pca(all_numeric_predictors(), num_comp = 4) %>% 
  prep() %>% 
  plot_top_loadings(component_number <= 4, n = 5) +
  scale_fill_brewer(palette = "Paired") +
  ggtitle("Principal Component Analysis with Loadings")
```

### Partial Least Squares

```{r}
#| warning: false
#| message: false
#| label: partial-least-squares
#| fig-width: 10


churn_rec_trained %>% 
  step_pls(all_numeric_predictors(), outcome = "Churn", num_comp = 4) %>% 
  plot_validation_results() +
  ggtitle("Partial Least Squares")

# plot the pls with loadings

churn_rec_trained %>% 
  step_pls(all_numeric_predictors(), outcome = "Churn", num_comp = 4) %>% 
  prep() %>% 
  plot_top_loadings(component_number <= 4, n = 5, type = "pls") +
  scale_fill_brewer(palette = "Paired") +
  ggtitle("Partial Least Squares with Loadings")
```

### Independent Component Analysis

```{r}
#| warning: false
#| message: false
#| label: ica
#| fig-width: 10

churn_rec_trained %>% 
  step_ica(all_numeric_predictors(), num_comp = 4) %>% 
  plot_validation_results() +
  ggtitle("Independent Component Analysis")
```

### Uniform Manifold Approximation and Projection

> UMAP is similar to the popular `t-SNE` method for nonlinear dimension reduction

```{r}
#| warning: false
#| message: false
#| label: umap
#| fig-width: 10

churn_rec_trained %>% 
  step_umap(all_numeric_predictors(), num_comp = 4) %>% 
  plot_validation_results() +
  ggtitle("UMAP")

churn_rec_trained %>% 
  step_umap(all_numeric_predictors(), num_comp = 4, outcome = "Churn") %>% 
  plot_validation_results() +
  ggtitle("UMAP (supervised)")
```


## Model Specification

None of the feature engineering methods examined is worth investigating in conjunction with different models.


```{r}
#| warning: false
#| message: false
#| label: model setup


# single-layer neural network

mlp_spec <- 
  mlp(hidden_units = tune(),
      penalty = tune(),
      epochs = tune()) %>% 
  set_engine("nnet") %>% 
  set_mode("classification")

# bagged trees

bagging_spec <- 
  bag_tree(cost_complexity = tune(),
           tree_depth = tune(), 
           min_n = tune(), 
           class_cost = tune()) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")

# xgboost 

xgb_spec <- 
  boost_tree(
    mtry = tune(),
    trees = tune(),
    min_n = tune(),
    tree_depth = tune(),
    learn_rate = tune(),
    loss_reduction = tune()
  ) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")


# lightGBM

lightGBM_spec <- 
  boost_tree(
    mode = "classification",
    mtry = tune(),
    trees = tune(),
    min_n = tune(),
    tree_depth = tune(),
    learn_rate = tune(),
    loss_reduction = tune(),
    sample_size = tune()
  ) %>% 
  set_engine("lightgbm")
```



### Apply Feature Engineering Procedures to the Recipe

```{r}
#| warning: false
#| message: false
#| label: apply-feature-engineering
#| eval: false
#| echo: false

pca_rec <- 
  churn_rec %>% 
  step_pca(all_numeric_predictors(), outcome = "Churn", num_comp = tune())

```

## Resampling

```{r}
#| label: resampling
#| warning: false
#| message: false

cltr <- control_grid(parallel_over = "everything")

churn_res <- 
  workflow_set(
    preproc = list(basic = Churn ~ .),
    models = list(bag = bagging_spec, 
                  mlp = mlp_spec,
                  xgboost = xgb_spec,
                  lightGBM = lightGBM_spec)
  ) %>% 
  workflow_map(
    verbose = TRUE,
    seed = 1603,
    resamples = churn_val,
    grid = 3,
    metrics = metric_set(roc_auc),
    control = cltr
  )

```


## Model Ranking

```{r}
#| label: model-ranking
#| warning: false
#| message: false


rankings <- 
  rank_results(churn_res, select_best = TRUE) %>% 
  mutate(method = map_chr(wflow_id, ~str_split(.x, "_", simplify = TRUE)[1]))

tidymodels_prefer()

rankings %>% filter(length(rank) > 0) %>% dplyr::select(rank, mean, model, method)
```



## Final Model

```{r}
#| label: final-model
#| warning: false
#| message: false
#| error: false


best_res <- 
  churn_res %>% 
  extract_workflow("basic_mlp") %>% 
  finalize_workflow(
    churn_res %>% 
      extract_workflow_set_result("basic_mlp") %>% 
      select_best(metric = "roc_auc")
  ) %>% 
  last_fit(split = churn_split, metrics = metric_set(roc_auc))

best_wflow_fit <- best_res$.workflow[[1]]

extract_fit_parsnip(best_wflow_fit)
```

## Model performance on test data

```{r}
#| label: performance-on-test-data
#| warning: false
#| message: false


collect_metrics(best_res)
```

## Roc Curve and AUC estimate

```{r}
#| label: roc-curve-auc-estimate
#| warning: false
#| message: false
#| comment: ""


prob_preds <- best_wflow_fit %>% 
  fit(churn_train) %>% 
  predict(churn_test, type = "prob") %>% 
  bind_cols(churn_test)


threshold_df <- prob_preds %>% 
  roc_curve(truth = Churn, estimate = `.pred_No`)
threshold_df %>% 
  autoplot()


roc_auc(prob_preds, truth = Churn, estimate = `.pred_No`)
```

### Confusion Matrix

```{r}
#| label: confusion-matrix
#| warning: false
#| message: false
#| comment: ""


mlp <- 
  best_wflow_fit %>% 
  fit(churn_train) %>% 
  predict(churn_test) %>% 
  bind_cols(churn_test)


mlp %>% 
  conf_mat(truth = Churn, estimate = .pred_class) %>% 
  summary()

mlp %>% 
  conf_mat(truth = Churn, estimate = .pred_class) %>% 
  autoplot(type = "heatmap")
```

# Variable Importance

Below is a plot of the variable importance. The importance of the features in the final model is represented visually.

```{r}
#| label: explainer
#| message: false
#| warning: false
#| eval: true


explain_stack <- DALEXtra::explain_tidymodels(best_wflow_fit, 
                                    data = churn_test %>% select(-Churn),
                                    y = as.numeric(churn_test$Churn),
                                    verbose = FALSE, 
                                    label ="telco-churn") 
```

```{r}
#| label: ggplot_imp_function
#| warning: false
#| message: false
#| eval: true

ggplot_imp <- function(...) {
  obj <- list(...)
  metric_name <- attr(obj[[1]], "loss_name")
  metric_lab <- paste(metric_name, 
                      "after permutations\n(higher indicates more important)")
  
  full_vip <- bind_rows(obj) %>%
    filter(variable != "_baseline_")
  
  perm_vals <- full_vip %>% 
    filter(variable == "_full_model_") %>% 
    group_by(label) %>% 
    summarise(dropout_loss = mean(dropout_loss))
  
  p <- full_vip %>%
    filter(variable != "_full_model_") %>% 
    mutate(variable = fct_reorder(variable, dropout_loss)) %>%
    ggplot(aes(dropout_loss, variable)) 
  if(length(obj) > 1) {
    p <- p + 
      facet_wrap(vars(label)) +
      geom_vline(data = perm_vals, aes(xintercept = dropout_loss, color = label),
                 size = 1.4, lty = 2, alpha = 0.7) +
      geom_boxplot(aes(color = label, fill = label), alpha = 0.2)
  } else {
    p <- p + 
      geom_vline(data = perm_vals, aes(xintercept = dropout_loss),
                 linewidth = 1.4, lty = 2, alpha = 0.7) +
      geom_boxplot(fill = "#91CBD765", alpha = 0.4)
    
  }
  p +
    theme(legend.position = "none") +
    labs(x = metric_lab, 
         y = NULL,  fill = NULL,  color = NULL)
}
```

```{r}
#| fig-cap: Global explainer for the classification ML tidymodel on the telco churn data
#| fig-width: 9
#| fig-height: 7
#| label: var-imp-plot
#| message: false
#| warning: false
#| eval: true


set.seed(1234)
  explain_stack %>% 
  model_parts() %>% 
  ggplot_imp()
```

From the relative variable importance plot above, `Partner`,`gender`, and `TechSupport` are the top 3 most important features in the final model whereas the `numTechTickets`, `tenure`, and `TotalCharges` features are  the least important among the selected features in the final model.

***

# Session Information

```{r}
#| label: session-info
#| message: false
#| warning: false
#| comment: ""
sessionInfo()
```
